{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차_텍스트마이닝(박영수).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ZL4MsZgkaM"
      },
      "source": [
        "아나콘다 에러\n",
        "\n",
        "- AttributeError: module 'tweepy' has no attribute 'StreamListener' 에러 날 경우 !pip install tweepy==3.10.0\n",
        "\n",
        "- Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl. 에러 날 경우 !pip install openpyxl\n",
        "\n",
        "- Jpype 에러 https://ellun.tistory.com/46"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shik1MueU0WO"
      },
      "source": [
        "## **1. 라이브러리 및 데이터 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "714Jz4_aUMML"
      },
      "source": [
        "#기본 라이브러리\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#시각화 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "#그래프 스타일 서식 지정\n",
        "plt.style.use('default')\n",
        "#그래프 한글 폰트\n",
        "from matplotlib import font_manager, rc\n",
        "plt.rc(\"font\", family = \"Malgun Gothic\")\n",
        "plt.rc(\"axes\", unicode_minus = False)\n",
        "\n",
        "#사이킷런\n",
        "from sklearn.datasets import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, RocCurveDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 텍스트 마이닝\n",
        "from konlpy.tag import Okt # 형태소 분석에 사용할 konlpy 패키지의 Okt 클래스를 임포트하고 okt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/data/')\n",
        "\n",
        "train_df  = pd.read_excel('5movies.xlsx')\n",
        "train_df .head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISW3dkIuVGFs"
      },
      "source": [
        "## **2. 결측값 제거**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4AbBEaeUbmx"
      },
      "source": [
        "# 댓글이 있는 항목만 담기(빈 댓글 삭제)\n",
        "# text 컬럼이 non-null인 샘플만 train_df에 다시 저장\n",
        "train_df = train_df[train_df['text'].notnull()]\n",
        "\n",
        "# 수정된 train_df의 정보를 다시 확인\n",
        "print(train_df.info())\n",
        "\n",
        "# 분류 클래스의 구성을 확인\n",
        "print(train_df['score'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4wI_DPzVJ7k"
      },
      "source": [
        "## **3. 분석 불가능한 문자 제거**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rWHEwLqU_xn"
      },
      "source": [
        "# 한글 외 문자 제거(옵션)\n",
        "import re # 정규식을 사용하기 위해 re 모듈을 임포트\n",
        "# ‘ㄱ ~‘힣’까지의 문자 제외한 나머지는 공백으로 치환, 영문: a-z | A-Z\n",
        "\n",
        "train_df['text'] = train_df['text'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
        "print(train_df.head())\n",
        "\n",
        "# Train용 데이터셋의 정보를 재확인\n",
        "print(train_df.info())\n",
        "text = train_df['text'] # 시리즈 객체로 저장\n",
        "score = train_df['score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye-iWrkQYJWE"
      },
      "source": [
        "## **4. 데이터 셋 분리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRUmMSC-Vl_6"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(text, score , test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmw2CzhaYcls"
      },
      "source": [
        "## **5. 토큰화 및 TF-IDF 벡터화**\n",
        "\n",
        "- 토큰화(tokenization)는 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나눔\n",
        "- 토큰화에서 고려해야 할 사항\n",
        "    1. 구두점이나 특수문자를 단순 제외해도 무방한지 확인 (ex, Ph.D, AT&T, $2,000, 11/22/1990, 45.34)\n",
        "    2. 줄임말과 단어 내 띄어쓰기 (we’re, thx, 고대, 영끌)\n",
        "    3. 한국어는 어절 독립단어가 아니므로 형태소(자립, 의존) 분해가 필요\n",
        "    4. 한국어는 띄어쓰기가 지켜지지 않고 있음\n",
        "- TF-IDF 벡터화(단어 빈도-역 문서 빈도: Term Frequency-Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya8SHcqKYZdd"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "okt = Okt()\n",
        "tfv = TfidfVectorizer(tokenizer=okt.morphs, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
        "tfv.fit(x_train)\n",
        "tfv_x_train = tfv.transform(x_train)\n",
        "print(tfv_x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSqHMx2-ZRwB"
      },
      "source": [
        "## **6. 감성 분석 모델 구축**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcde_JuUYv6o"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import GridSearchCV # 하이퍼 파라미터 최적화\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "params = {'C': [15, 18, 19, 20, 22]}\n",
        "grid_cv = GridSearchCV(clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv.fit(tfv_x_train, y_train)\n",
        "\n",
        "# 최적의 평가 파라미터는 grid_cv.best_estimator_에 저장됨\n",
        "print(grid_cv.best_params_, grid_cv.best_score_)# 가장 적합한 파라메터, 최고 정확도 확인"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz34a0JUZo-j"
      },
      "source": [
        "## **7. 분석 모델 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4a0G8lBZdOp"
      },
      "source": [
        "tfv_x_test = tfv.transform(x_test)\n",
        "\n",
        "# test_predict = grid_cv.best_estimator_.score(tfv_test_x,test_y)\n",
        "\n",
        "test_predict = grid_cv.best_estimator_.predict(tfv_x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('감성 분류 모델의 정확도 : ',round(accuracy_score(y_test, test_predict), 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QthpBpe1Z8AK"
      },
      "source": [
        "## **8. 감성 예측**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ERPkWcBZ4CV"
      },
      "source": [
        "input_text = '딱히 대단한 재미도 감동도 없는데 ~! 너무 과대 평과된 영화 중 하나'\n",
        "#입력 텍스트에 대한 전처리 수행\n",
        "input_text = re.compile(r'[ㄱ-ㅣ가-힣]+').findall(input_text)\n",
        "print(input_text)\n",
        "input_text = [\" \".join(input_text)]\n",
        "print(input_text)\n",
        "# 입력 텍스트의 피처 벡터화\n",
        "st_tfidf = tfv.transform(input_text)\n",
        "print(st_tfidf)\n",
        "\n",
        "# 최적 감성 분석 모델에 적용하여 감성 분석 평가\n",
        "st_predict = grid_cv.best_estimator_.predict(st_tfidf)\n",
        "\n",
        "#예측 결과 출력\n",
        "if(st_predict == 0):\n",
        "    print('예측 결과: ->> 부정 감성')\n",
        "else :\n",
        "    print('예측 결과: ->> 긍정 감성')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPbVOSc-aXIB"
      },
      "source": [
        "## **9. 출처**\n",
        "\n",
        "https://velog.io/@changhtun1/Python-%EC%86%8C%EC%85%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EA%B0%90%EC%84%B1-%EC%98%88%EC%B8%A1"
      ]
    }
  ]
}